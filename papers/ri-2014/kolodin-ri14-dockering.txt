М.Ю.Колодин 
СПИИРАН, Санкт-Петербург
научный сотрудник
myke@mail.ru

Оптимизация программных конфигураций на основе систем лёгкой виртуализации

Для выполнения анализа работы некоторой программной системы и оптимизации её параметров традиционно используются ряд способов: непосредственный запуск системы с известным набором параметров и последующий анализ её работы; программное моделирование системы; запуск её в рамках системы управления виртуальными машинами; каждый из способов имеет свои достоинства и недостатки. В первом случае велика цена ошибки в любой из составляющих процесса; во втором случае имеются большие затраты на создание системы моделирования, кроме того, она вносит существенные искажения в процесс; в третьем случае система работает в окружении, близком к реальному, но высока нагрузка на базовую систему; во всех случаях трудно запустить одновременно большое количество экземпляров исследуемых систем для изучения их совместной работы в условиях высоких нагрузок.

Хорошим компромиссом может стать применение систем лёгкой виртуализации на основе контейнеров Linux (LXC) и особенно технологии docker. В ней накладные расходы на создание и запуск виртуальных машин крайне низки, а изучаемая система работает в условиях, максимально близких к реальным. Есть и средства автоматизации работы с контейнерами и управления сборками программных конфигураций.

Таким образом, в целом подход состоит в следующем. Нужно выполнить первичное конфигурирование системы, сформировать её выполняемый образ. Затем его можно многократно выполнять с различными наборами параметров, изучать правильность работы, потребление ресурсов, выполнять перенастройку параметров, находить места, подлежащие оптимизации. Можно и заранее рассчитывать требуемые наборы параметров, формировать образы систем на их основе и выполнять необходимые тесты. Интересным, но ресурсоёмким является подход с «матричной» генерацией наборов систем и их параллельным или последовательным выполнением. В отличие от классических систем виртуализации (VMWare, VirtualBox и подобных) в данном случае можно запускать десятки и сотни экземпляров систем на обычном оборудовании. Исходным ограничением является только использование систем и программ на основе ОС Linux; однако уже есть успешные  реализации на ОС MS Windows и иных.

Здесь важна минимизация накладных затрат на моделирование и общее приближение выполнения задачи к реальному режиму работы. В то же время нам нужно уметь взаимодействовать с запущенными программами во всех параллельно работающих виртуальных машинах, управлять ими, оперативно снимать данных об их работе, в т.ч. о загруженности процессора, потреблении оперативной памяти и дискового пространства, для веб-серверов и серверов баз данных – о числе успешных обращений  в секунду.

Вся подобная информация пишется в файлы протоколов, причём для снижения воздействия на исследуемые системы по мере возможности снимаемая информация хранится в оперативной памяти или пересылается по быстрой локальной сети на обрабатывающий сервер. Результаты оперативно показывается экспериментатору на экране веб-браузера, для чего как в управляющей системе, так и иногда в подчинённых запущены простые веб-сервера. Большая часть взаимодействия между машинами проходит по протоколу ssh. Основная часть анализа результатов выполняется после эксперимента.

Классическая оптимизация состоит в данном случае в подборе в некотором смысле наилучших наборов параметров. Метаоптимизация включает также модификацию структуры системы: обе системы, тестирующую и тестируемую, можно рассматривать как многоуровневые, и тогда можно в соответствии с процессом моделирования, его результатами изменять конфигурацию тестирующей системы, а не только тестируемой.

Изучались различные языки программирования (python, julia, c++, go, factor) и пакеты для управления виртуализацией и автоматизацией сборок. Для работы со многими параллельно или последовательно работающими наборами виртуальных машин используются настройки и данные в общей памяти (файлах на реальной машине), что даёт равные условия для отдельных машин; вообще для чистоты эксперимента нужно максимально исключить взаимное влияние подсистем друг на друга. Причина проста: нужны не просто быстрые инструменты моделирования и получения оценок, а более быстрые по сравнению с прочими подсистемами, участвующими в  процессе.

Для оценки конфигураций выполнялось нагрузочное тестирование, напр., посредством пакета ab (apache benchmark), со сбором большого количества данных и их анализом.

Полученные результаты интересны и могут быть практически применены в несложных (по наборам параметров) системах; но требуется получать более наглядную обработку собираемых данных (диаграммы в дополнение к таблицам),  для согласования подсистем пользоваться базами данных с хранением данных в оперативной памяти, очередями сообщений типа ZMQ, а результаты передавать по быстрой локальной сети на другой сервер, на котором и смотреть оперативные отчёты; в этом направлении и будет выполняться дальнейшее исследование.

---

* План исследования

...

* План отчёта

...

* Что показывается на презентации?
какие картинки?
...

* Точный перечень используемых средств
OS Linux Mint 17 Cinnamon
Python 2.7
   psutil
Docker 1.2.0
fig 1.0.0.
curl 7.35.0
...

?
ZMQ, RabbitMQ...
sqlite
flask, bottle
matplotlib,...
ipython, ipynb
julia, ijulia

ранее
Oracle VirtualBox
vagrant
ansible

* Детали, загрузки, образы и т.п.

www.fig.sh

https://registry.hub.docker.com/u/devries/bottle/dockerfile/
devries / bottle
A base image for building python apps with the bottle framework and gunicorn WSGI server.

* Ссылки

- psutil 

https://pypi.python.org/pypi?:action=display&name=psutil#downloads
https://github.com/giampaolo/psutil
https://pythonhosted.org/psutil/

- logging 

https://docs.python.org/2/howto/logging.html
http://habrahabr.ru/post/144566/

-- docker.py

https://www.digitalocean.com/community/tutorials/docker-explained-how-to-containerize-python-web-applications
The threat of having a web application hijacked and used for taking over the entire host is a vast and scary one. It has long been a challenge to keep things isolated from one another for enhanced security, especially if the applications belong to different clients. Many measures can be taken to prevent this unfortunate scenario, however, they are usually too costly (both on time and resources) or too complicated for most developers' or administrators' use cases.

In this DigitalOcean article, we'll talk about "containerizing" Python web applications in order to have them in very secure sandboxes, absolutely kept within their own environments (unless you explicitly "link" them to another). In order to achieve this, we'll see about creating a docker container to host a Python web application step-by-step, finally bootstrapping our build processes with a Dockerfile to fully automate it.

-- http://serverascode.com/2014/06/05/docker-python.html
Using Docker with Python and iPython

-- http://stackoverflow.com/questions/24228630/how-to-use-docker-py-official-docker-client-to-start-a-bash-shell
https://github.com/d11wtq/dockerpty

-- https://docs.docker.com/reference/api/remote_api_client_libraries/
Docker Remote API Client Libraries

-- https://github.com/docker/docker-py

-- http://blog.bordage.pro/avoid-docker-py/
errors and real start

-- https://github.com/d11wtq/dockerpty
OK
import docker
import dockerpty

client = docker.Client()
container = client.create_container(
    image='busybox:latest',
    stdin_open=True,
    tty=True,
    command='/bin/sh',
)

dockerpty.start(client, container)
# starts a #session 


